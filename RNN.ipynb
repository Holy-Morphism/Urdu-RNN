{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Holy-Morphism/Urdu-RNN/blob/main/RNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y8eBqscKBkKC"
      },
      "source": [
        "# **Implementing Many-to-Many RNN for English-to-Urdu Language Translation and Exploring Its Limitations**\n",
        "\n",
        "# **Part 1:** Many-to-Many Recurrent Neural Network (RNN) Implementation\n",
        "\n",
        "## Data Preparation:\n",
        "\n",
        "### Loading the Data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "id": "dfQ_cl5TBkKG",
        "outputId": "7eea305f-f902-4c60-c3e5-b097ac15eb0a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                           SENTENCES  \\\n",
              "0             How can I communicate with my parents?   \n",
              "1                           How can I make friends?’   \n",
              "2                              Why do I get so sad?’   \n",
              "3  If you’ve asked yourself such questions, you’r...   \n",
              "4  Depending on where you’ve turned for guidance,...   \n",
              "\n",
              "                                             MEANING  \n",
              "0                 میں اپنے والدین سے کیسے بات کروں ؟  \n",
              "1                             میں دوست کیسے بنائوں ؟  \n",
              "2                           میں اتنا اداس کیوں ہوں؟.  \n",
              "3  اگر آپ نے اپنے آپ سے ایسے سوالات کیے ہیں، تو آ...  \n",
              "4   اس بات پر منحصر ہے کہ آپ رہنمائی کے لیے کہاں ...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ab0a7436-88a1-43a1-a11d-9e57a0b29e0f\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>SENTENCES</th>\n",
              "      <th>MEANING</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>How can I communicate with my parents?</td>\n",
              "      <td>میں اپنے والدین سے کیسے بات کروں ؟</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>How can I make friends?’</td>\n",
              "      <td>میں دوست کیسے بنائوں ؟</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Why do I get so sad?’</td>\n",
              "      <td>میں اتنا اداس کیوں ہوں؟.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>If you’ve asked yourself such questions, you’r...</td>\n",
              "      <td>اگر آپ نے اپنے آپ سے ایسے سوالات کیے ہیں، تو آ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Depending on where you’ve turned for guidance,...</td>\n",
              "      <td>اس بات پر منحصر ہے کہ آپ رہنمائی کے لیے کہاں ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ab0a7436-88a1-43a1-a11d-9e57a0b29e0f')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ab0a7436-88a1-43a1-a11d-9e57a0b29e0f button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ab0a7436-88a1-43a1-a11d-9e57a0b29e0f');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-cc028058-2bc4-4516-b224-de92d640749b\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-cc028058-2bc4-4516-b224-de92d640749b')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-cc028058-2bc4-4516-b224-de92d640749b button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 29496,\n  \"fields\": [\n    {\n      \"column\": \"SENTENCES\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 23113,\n        \"samples\": [\n          \"Reasonable not too good\",\n          \"Highly recommend for spicy food lover.best koila karai in karachi.dehly style test.\",\n          \"Best dinein place in SITE area with emphasis on quality food and hygiene\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"MEANING\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 22557,\n        \"samples\": [\n          \" \\u0627\\u06cc\\u06a9 \\u0628\\u0627\\u062f\\u0644 \\u0627\\u0633 \\u06a9\\u06cc \\u067e\\u06cc\\u0634\\u0627\\u0646\\u06cc \\u06a9\\u06d2 \\u0627\\u0648\\u067e\\u0631 \\u0633\\u06d2 \\u06af\\u0632\\u0631\\u0627 \\u062c\\u0628 \\u0627\\u0633 \\u0646\\u06d2 \\u06a9\\u06c1\\u0627: \\\"\\u0646\\u06c1\\u06cc\\u06ba\\u060c \\u062c\\u0646\\u0627\\u0628\\u060c \\u0645\\u06cc\\u06ba \\u062a\\u062d\\u0631\\u06cc\\u0631 \\u0646\\u06c1\\u06cc\\u06ba \\u062c\\u0627\\u0646\\u062a\\u0627\\u060c \\u0627\\u0648\\u0631 \\u067e\\u06be\\u0631 \\u0628\\u06be\\u06cc \\u06cc\\u06c1 \\u0642\\u0627\\u0628\\u0644 \\u0628\\u0631\\u062f\\u0627\\u0634\\u062a \\u062d\\u062f \\u062a\\u06a9 \\u0633\\u0627\\u062f\\u06c1 \\u06c1\\u06d2\\u06d4\",\n          \"(\\u06af\\u0648\\u06af\\u0644 \\u06a9\\u06d2 \\u0630\\u0631\\u06cc\\u0639\\u06c1 \\u062a\\u0631\\u062c\\u0645\\u06c1 \\u06a9\\u06cc\\u0627 \\u06af\\u06cc\\u0627) \\u0627\\u06cc\\u06a9 \\u0628\\u0631\\u062a\\u0646 \\u06a9\\u06d2 \\u0633\\u0627\\u062a\\u06be \\u0628\\u06c1\\u062a \\u0627\\u0686\\u06be\\u0627 (\\u0627\\u0635\\u0644) \\u0632\\u0628\\u0631\\u062f\\u0633\\u062a \\u0646\\u06c1\\u0627\\u0631\\u06cc\",\n          \" \\u0645\\u062c\\u06be\\u06d2 \\u06cc\\u06c1 \\u062c\\u0627\\u0646 \\u06a9\\u0631 \\u062e\\u0648\\u0634\\u06cc \\u06c1\\u0648\\u06af\\u06cc \\u06a9\\u06c1 \\u0622\\u067e \\u06a9\\u06cc \\u0628\\u06cc\\u0645\\u0627\\u0631 \\u062c\\u0630\\u0628\\u0627\\u062a\\u06cc\\u062a \\u0627\\u0648\\u0631 \\u0631\\u06cc\\u0627\\u0633\\u062a \\u06a9\\u06d2 \\u0645\\u0639\\u0627\\u0645\\u0644\\u0627\\u062a \\u06a9\\u06d2 \\u062f\\u0631\\u0645\\u06cc\\u0627\\u0646 \\u0645\\u0645\\u06a9\\u0646\\u06c1 \\u0637\\u0648\\u0631 \\u067e\\u0631 \\u06a9\\u06cc\\u0627 \\u062a\\u0639\\u0644\\u0642 \\u06c1\\u0648 \\u0633\\u06a9\\u062a\\u0627 \\u06c1\\u06d2! \\u2019\\u2019\\u0627\\u0648\\u06c1 \\u0645\\u0627\\u06ba!\\u2018\\u2018 \\u0631\\u06cc\\u0646\\u06cc \\u0628\\u0691\\u0628\\u0691\\u0627\\u0626\\u06cc\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_excel('./parallel-corpus.xlsx')\n",
        "\n",
        "# Keep only the first two columns\n",
        "df = df.iloc[:, :2]\n",
        "\n",
        "df.rename(columns = {'SENTENCES ':'SENTENCES'}, inplace = True)\n",
        "\n",
        "df = df.dropna()\n",
        "df = df[df['SENTENCES'].str.len() > 3]\n",
        "\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cy1yA38HBkKI"
      },
      "source": [
        "### Preprocess data in both English and Urdu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "heK7hl3DBkKJ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Tokenize the sentences\n",
        "tokenizer_eng = Tokenizer()\n",
        "tokenizer_urdu = Tokenizer()\n",
        "\n",
        "# Convert the 'SENTENCES' and 'MEANING' columns to string type before fitting the tokenizer\n",
        "df['SENTENCES'] = df['SENTENCES'].astype(str)\n",
        "df['MEANING'] = df['MEANING'].astype(str)\n",
        "\n",
        "# Fit the tokenizers on English and Urdu texts\n",
        "tokenizer_eng.fit_on_texts(df['SENTENCES'])\n",
        "tokenizer_urdu.fit_on_texts(df['MEANING'])\n",
        "\n",
        "# Convert texts to sequences\n",
        "eng_sequences = tokenizer_eng.texts_to_sequences(df['SENTENCES'])\n",
        "urdu_sequences = tokenizer_urdu.texts_to_sequences(df['MEANING'])\n",
        "\n",
        "# Pad sequences to the same length\n",
        "max_len_eng = max(len(seq) for seq in eng_sequences)\n",
        "max_len_urdu = max(len(seq) for seq in urdu_sequences)\n",
        "max_len = max(max_len_eng, max_len_urdu)\n",
        "\n",
        "eng_sequences = pad_sequences(eng_sequences, maxlen=max_len, padding='post')\n",
        "urdu_sequences = pad_sequences(urdu_sequences, maxlen=max_len, padding='post')\n",
        "\n",
        "# Vocabulary sizes\n",
        "vocab_size_eng = len(tokenizer_eng.word_index) + 1\n",
        "vocab_size_urdu = len(tokenizer_urdu.word_index) + 1\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ac_QVU3wBkKK"
      },
      "source": [
        "### Split the dataset into training, validation, and test sets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "rmfxvpX9BkKK"
      },
      "outputs": [],
      "source": [
        "# Split the data into training, validation, and test sets\n",
        "train_size = int(len(eng_sequences) * 0.7)\n",
        "test_size = int(len(eng_sequences) * 0.15)\n",
        "\n",
        "# For English (input) sequences\n",
        "x_train, x_temp = eng_sequences[:train_size], eng_sequences[train_size:]\n",
        "x_test, x_val = x_temp[:test_size], x_temp[test_size:]\n",
        "\n",
        "# For Urdu (target) sequences\n",
        "y_train, y_temp = urdu_sequences[:train_size], urdu_sequences[train_size:]\n",
        "y_test, y_val = y_temp[:test_size], y_temp[test_size:]\n",
        "\n",
        "# Prepare decoder input data (shifted by one position)\n",
        "decoder_input_data = np.zeros_like(urdu_sequences)\n",
        "decoder_input_data[:, 1:] = urdu_sequences[:, :-1]\n",
        "decoder_input_data[:, 0] = tokenizer_urdu.word_index.get('<start>', 0)  # Use a start token if defined\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7XkoIjbHS8Hk",
        "outputId": "f28f32dd-c74c-4b3d-d582-445e3d614b85"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(20647, 938) (20647, 938)\n"
          ]
        }
      ],
      "source": [
        "print(x_train.shape, y_train.shape )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k4WkDPvwBkKL"
      },
      "source": [
        "## Model Architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "pZII0cIeBkKL"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, SimpleRNN, Dense, Embedding\n",
        "\n",
        "# Encoder model\n",
        "encoder_inputs = Input(shape=(None,))\n",
        "encoder_embedding = Embedding(input_dim=vocab_size_eng, output_dim=64)(encoder_inputs)\n",
        "encoder_rnn = SimpleRNN(64, return_state=True)\n",
        "encoder_outputs, state_h = encoder_rnn(encoder_embedding)\n",
        "encoder_states = [state_h]  # For SimpleRNN, we only need the hidden state\n",
        "\n",
        "# Decoder model\n",
        "decoder_inputs = Input(shape=(None,))\n",
        "decoder_embedding = Embedding(input_dim=vocab_size_urdu, output_dim=64)(decoder_inputs)\n",
        "decoder_rnn = SimpleRNN(64, return_sequences=True, return_state=True)\n",
        "decoder_outputs, _ = decoder_rnn(decoder_embedding, initial_state=encoder_states)\n",
        "decoder_dense = Dense(vocab_size_urdu, activation='softmax')\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "\n",
        "# Print the model summary\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "id": "5P3UguilUUav",
        "outputId": "7ac359cf-4e44-4ab5-a405-36e7677945b8"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)           │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ input_layer_1             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)           │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │      \u001b[38;5;34m1,057,280\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ embedding_1 (\u001b[38;5;33mEmbedding\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │      \u001b[38;5;34m1,130,112\u001b[0m │ input_layer_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ simple_rnn (\u001b[38;5;33mSimpleRNN\u001b[0m)    │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,    │          \u001b[38;5;34m8,256\u001b[0m │ embedding[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "│                           │ \u001b[38;5;34m64\u001b[0m)]                   │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ simple_rnn_1 (\u001b[38;5;33mSimpleRNN\u001b[0m)  │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m),     │          \u001b[38;5;34m8,256\u001b[0m │ embedding_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],     │\n",
              "│                           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)]            │                │ simple_rnn[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m1\u001b[0m]       │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m17658\u001b[0m)    │      \u001b[38;5;34m1,147,770\u001b[0m │ simple_rnn_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)              </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">        Param # </span>┃<span style=\"font-weight: bold\"> Connected to           </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ input_layer_1             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,057,280</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,130,112</span> │ input_layer_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ simple_rnn (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SimpleRNN</span>)    │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │ embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "│                           │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)]                   │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ simple_rnn_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SimpleRNN</span>)  │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>),     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │ embedding_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],     │\n",
              "│                           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)]            │                │ simple_rnn[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>]       │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">17658</span>)    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,147,770</span> │ simple_rnn_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,351,674\u001b[0m (12.79 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,351,674</span> (12.79 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,351,674\u001b[0m (12.79 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,351,674</span> (12.79 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uKW39VtfVb-N",
        "outputId": "9bef7950-2e94-4380-fa1e-2e2eec51d665"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m646/646\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m271s\u001b[0m 419ms/step - accuracy: 0.9828 - loss: 0.1312 - val_accuracy: 0.9823 - val_loss: 0.1688\n",
            "Epoch 2/50\n",
            "\u001b[1m646/646\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m297s\u001b[0m 380ms/step - accuracy: 0.9839 - loss: 0.1121 - val_accuracy: 0.9817 - val_loss: 0.1768\n",
            "Epoch 3/50\n",
            "\u001b[1m646/646\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m263s\u001b[0m 381ms/step - accuracy: 0.9844 - loss: 0.1047 - val_accuracy: 0.9808 - val_loss: 0.1855\n",
            "Epoch 4/50\n",
            "\u001b[1m646/646\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m263s\u001b[0m 383ms/step - accuracy: 0.9844 - loss: 0.1016 - val_accuracy: 0.9810 - val_loss: 0.1887\n",
            "Epoch 5/50\n",
            "\u001b[1m646/646\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m262s\u001b[0m 382ms/step - accuracy: 0.9850 - loss: 0.0951 - val_accuracy: 0.9811 - val_loss: 0.1923\n",
            "Epoch 6/50\n",
            "\u001b[1m646/646\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m261s\u001b[0m 380ms/step - accuracy: 0.9852 - loss: 0.0926 - val_accuracy: 0.9807 - val_loss: 0.1981\n",
            "Epoch 7/50\n",
            "\u001b[1m646/646\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m262s\u001b[0m 381ms/step - accuracy: 0.9854 - loss: 0.0902 - val_accuracy: 0.9808 - val_loss: 0.2014\n",
            "Epoch 8/50\n",
            "\u001b[1m646/646\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m263s\u001b[0m 382ms/step - accuracy: 0.9853 - loss: 0.0895 - val_accuracy: 0.9805 - val_loss: 0.2064\n",
            "Epoch 9/50\n",
            "\u001b[1m646/646\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m261s\u001b[0m 381ms/step - accuracy: 0.9857 - loss: 0.0861 - val_accuracy: 0.9806 - val_loss: 0.2089\n",
            "Epoch 10/50\n",
            "\u001b[1m646/646\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m246s\u001b[0m 381ms/step - accuracy: 0.9857 - loss: 0.0849 - val_accuracy: 0.9805 - val_loss: 0.2120\n",
            "Epoch 11/50\n",
            "\u001b[1m646/646\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m263s\u001b[0m 382ms/step - accuracy: 0.9857 - loss: 0.0839 - val_accuracy: 0.9805 - val_loss: 0.2146\n",
            "Epoch 12/50\n",
            "\u001b[1m646/646\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m246s\u001b[0m 381ms/step - accuracy: 0.9862 - loss: 0.0798 - val_accuracy: 0.9804 - val_loss: 0.2187\n",
            "Epoch 13/50\n",
            "\u001b[1m646/646\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m245s\u001b[0m 380ms/step - accuracy: 0.9861 - loss: 0.0796 - val_accuracy: 0.9805 - val_loss: 0.2205\n",
            "Epoch 14/50\n",
            "\u001b[1m646/646\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m247s\u001b[0m 382ms/step - accuracy: 0.9864 - loss: 0.0771 - val_accuracy: 0.9805 - val_loss: 0.2230\n",
            "Epoch 15/50\n",
            "\u001b[1m646/646\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m262s\u001b[0m 383ms/step - accuracy: 0.9864 - loss: 0.0761 - val_accuracy: 0.9804 - val_loss: 0.2262\n",
            "Epoch 16/50\n",
            "\u001b[1m646/646\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m262s\u001b[0m 383ms/step - accuracy: 0.9864 - loss: 0.0754 - val_accuracy: 0.9804 - val_loss: 0.2293\n",
            "Epoch 17/50\n",
            "\u001b[1m646/646\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m261s\u001b[0m 382ms/step - accuracy: 0.9868 - loss: 0.0730 - val_accuracy: 0.9804 - val_loss: 0.2314\n",
            "Epoch 18/50\n",
            "\u001b[1m646/646\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m262s\u001b[0m 382ms/step - accuracy: 0.9867 - loss: 0.0729 - val_accuracy: 0.9804 - val_loss: 0.2349\n",
            "Epoch 19/50\n",
            "\u001b[1m646/646\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m261s\u001b[0m 381ms/step - accuracy: 0.9870 - loss: 0.0708 - val_accuracy: 0.9805 - val_loss: 0.2361\n",
            "Epoch 20/50\n",
            "\u001b[1m646/646\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m262s\u001b[0m 381ms/step - accuracy: 0.9869 - loss: 0.0708 - val_accuracy: 0.9803 - val_loss: 0.2394\n",
            "Epoch 21/50\n",
            "\u001b[1m646/646\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m263s\u001b[0m 383ms/step - accuracy: 0.9872 - loss: 0.0686 - val_accuracy: 0.9804 - val_loss: 0.2409\n",
            "Epoch 22/50\n",
            "\u001b[1m646/646\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m262s\u001b[0m 384ms/step - accuracy: 0.9873 - loss: 0.0677 - val_accuracy: 0.9804 - val_loss: 0.2440\n",
            "Epoch 23/50\n",
            "\u001b[1m646/646\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m262s\u001b[0m 383ms/step - accuracy: 0.9874 - loss: 0.0672 - val_accuracy: 0.9803 - val_loss: 0.2475\n",
            "Epoch 24/50\n",
            "\u001b[1m646/646\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m261s\u001b[0m 381ms/step - accuracy: 0.9874 - loss: 0.0667 - val_accuracy: 0.9804 - val_loss: 0.2488\n",
            "Epoch 25/50\n",
            "\u001b[1m646/646\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m262s\u001b[0m 382ms/step - accuracy: 0.9876 - loss: 0.0655 - val_accuracy: 0.9804 - val_loss: 0.2517\n",
            "Epoch 26/50\n",
            "\u001b[1m646/646\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m263s\u001b[0m 384ms/step - accuracy: 0.9875 - loss: 0.0661 - val_accuracy: 0.9803 - val_loss: 0.2536\n",
            "Epoch 27/50\n",
            "\u001b[1m646/646\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m262s\u001b[0m 383ms/step - accuracy: 0.9878 - loss: 0.0640 - val_accuracy: 0.9803 - val_loss: 0.2548\n",
            "Epoch 28/50\n",
            "\u001b[1m646/646\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m262s\u001b[0m 383ms/step - accuracy: 0.9879 - loss: 0.0634 - val_accuracy: 0.9803 - val_loss: 0.2565\n",
            "Epoch 29/50\n",
            "\u001b[1m646/646\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m262s\u001b[0m 383ms/step - accuracy: 0.9878 - loss: 0.0636 - val_accuracy: 0.9803 - val_loss: 0.2590\n",
            "Epoch 30/50\n",
            "\u001b[1m646/646\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m261s\u001b[0m 381ms/step - accuracy: 0.9879 - loss: 0.0632 - val_accuracy: 0.9803 - val_loss: 0.2604\n",
            "Epoch 31/50\n",
            "\u001b[1m646/646\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m246s\u001b[0m 380ms/step - accuracy: 0.9883 - loss: 0.0613 - val_accuracy: 0.9803 - val_loss: 0.2629\n",
            "Epoch 32/50\n",
            "\u001b[1m646/646\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m264s\u001b[0m 383ms/step - accuracy: 0.9882 - loss: 0.0611 - val_accuracy: 0.9803 - val_loss: 0.2640\n",
            "Epoch 33/50\n",
            "\u001b[1m646/646\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m261s\u001b[0m 381ms/step - accuracy: 0.9883 - loss: 0.0606 - val_accuracy: 0.9803 - val_loss: 0.2656\n",
            "Epoch 34/50\n",
            "\u001b[1m646/646\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m262s\u001b[0m 382ms/step - accuracy: 0.9883 - loss: 0.0604 - val_accuracy: 0.9803 - val_loss: 0.2664\n",
            "Epoch 35/50\n",
            "\u001b[1m646/646\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m263s\u001b[0m 383ms/step - accuracy: 0.9886 - loss: 0.0591 - val_accuracy: 0.9802 - val_loss: 0.2673\n",
            "Epoch 36/50\n",
            "\u001b[1m646/646\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m262s\u001b[0m 383ms/step - accuracy: 0.9883 - loss: 0.0603 - val_accuracy: 0.9803 - val_loss: 0.2681\n",
            "Epoch 37/50\n",
            "\u001b[1m646/646\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m246s\u001b[0m 380ms/step - accuracy: 0.9887 - loss: 0.0584 - val_accuracy: 0.9803 - val_loss: 0.2700\n",
            "Epoch 38/50\n",
            "\u001b[1m646/646\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m263s\u001b[0m 383ms/step - accuracy: 0.9885 - loss: 0.0594 - val_accuracy: 0.9803 - val_loss: 0.2707\n",
            "Epoch 39/50\n",
            "\u001b[1m646/646\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m261s\u001b[0m 382ms/step - accuracy: 0.9887 - loss: 0.0582 - val_accuracy: 0.9802 - val_loss: 0.2725\n",
            "Epoch 40/50\n",
            "\u001b[1m646/646\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m263s\u001b[0m 383ms/step - accuracy: 0.9887 - loss: 0.0578 - val_accuracy: 0.9803 - val_loss: 0.2740\n",
            "Epoch 41/50\n",
            "\u001b[1m646/646\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m262s\u001b[0m 383ms/step - accuracy: 0.9888 - loss: 0.0577 - val_accuracy: 0.9803 - val_loss: 0.2741\n",
            "Epoch 42/50\n",
            "\u001b[1m646/646\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m261s\u001b[0m 382ms/step - accuracy: 0.9889 - loss: 0.0569 - val_accuracy: 0.9803 - val_loss: 0.2747\n",
            "Epoch 43/50\n",
            "\u001b[1m646/646\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m263s\u001b[0m 383ms/step - accuracy: 0.9890 - loss: 0.0563 - val_accuracy: 0.9802 - val_loss: 0.2752\n",
            "Epoch 44/50\n",
            "\u001b[1m646/646\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m247s\u001b[0m 382ms/step - accuracy: 0.9890 - loss: 0.0563 - val_accuracy: 0.9803 - val_loss: 0.2761\n",
            "Epoch 45/50\n",
            "\u001b[1m646/646\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m263s\u001b[0m 383ms/step - accuracy: 0.9890 - loss: 0.0564 - val_accuracy: 0.9803 - val_loss: 0.2773\n",
            "Epoch 46/50\n",
            "\u001b[1m646/646\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m261s\u001b[0m 382ms/step - accuracy: 0.9888 - loss: 0.0569 - val_accuracy: 0.9803 - val_loss: 0.2779\n",
            "Epoch 47/50\n",
            "\u001b[1m646/646\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m262s\u001b[0m 381ms/step - accuracy: 0.9890 - loss: 0.0561 - val_accuracy: 0.9803 - val_loss: 0.2778\n",
            "Epoch 48/50\n",
            "\u001b[1m646/646\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m262s\u001b[0m 382ms/step - accuracy: 0.9891 - loss: 0.0556 - val_accuracy: 0.9803 - val_loss: 0.2795\n",
            "Epoch 49/50\n",
            "\u001b[1m646/646\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m262s\u001b[0m 382ms/step - accuracy: 0.9891 - loss: 0.0553 - val_accuracy: 0.9802 - val_loss: 0.2814\n",
            "Epoch 50/50\n",
            "\u001b[1m646/646\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m262s\u001b[0m 381ms/step - accuracy: 0.9890 - loss: 0.0559 - val_accuracy: 0.9802 - val_loss: 0.2813\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7d95b7d135e0>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "# Train the model\n",
        "model.fit(\n",
        "    [x_train, decoder_input_data[:train_size]], y_train,\n",
        "    epochs=50,\n",
        "    validation_data=([x_val, decoder_input_data[train_size:train_size + len(x_val)]], y_val)\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z1sZoa8uTtQ6"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Model to generate predictions (inference mode for encoder)\n",
        "encoder_model = Model(encoder_inputs, encoder_states)\n",
        "\n",
        "# Re-define the decoder model to use states from encoder during inference\n",
        "decoder_state_input_h = Input(shape=(64,))\n",
        "# decoder_state_input_c = Input(shape=(64,)) # Remove this line as SimpleRNN only uses hidden state\n",
        "# decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c] # Change this line\n",
        "decoder_states_inputs = [decoder_state_input_h] # SimpleRNN only needs hidden state\n",
        "\n",
        "decoder_outputs, state_h = decoder_rnn(\n",
        "    decoder_embedding, initial_state=decoder_states_inputs)\n",
        "decoder_states = [state_h]\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "decoder_model = Model(\n",
        "    [decoder_inputs] + decoder_states_inputs, # Updated to reflect change above\n",
        "    [decoder_outputs] + decoder_states\n",
        ")\n",
        "\n",
        "# Function to convert sequence to words\n",
        "def sequence_to_text(tokenizer, sequence):\n",
        "    reverse_word_index = {index: word for word, index in tokenizer.word_index.items()}\n",
        "    return [reverse_word_index.get(i, '<unk>') for i in sequence]\n",
        "\n",
        "# Function to generate translation for an input sequence\n",
        "def translate_sequence(input_seq):\n",
        "    # Encode the input as state vectors\n",
        "    states_value = encoder_model.predict(input_seq)\n",
        "\n",
        "\n",
        "\n",
        "    # Generate the start token\n",
        "    target_seq = np.zeros((1, 1))\n",
        "    target_seq[0, 0] = tokenizer_urdu.word_index.get('<start>', 0)\n",
        "\n",
        "    stop_condition = False\n",
        "    translated_sentence = []\n",
        "\n",
        "    while not stop_condition:\n",
        "        # states_value_reshaped = states_value[0].reshape(1, states_value[0].shape[0]) # reshape to (1, 64)\n",
        "\n",
        "        # Pass the reshaped state as both h and c (since SimpleRNN only uses h)\n",
        "        output_tokens, h = decoder_model.predict([target_seq] + [states_value]) # Change this line\n",
        "\n",
        "        # Sample a token\n",
        "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "        sampled_word = tokenizer_urdu.index_word.get(sampled_token_index, '<unk>')\n",
        "\n",
        "        if sampled_word == '<end>' or len(translated_sentence) > max_len:\n",
        "            stop_condition = True\n",
        "        else:\n",
        "            translated_sentence.append(sampled_word)\n",
        "\n",
        "        # Update the target sequence (of length 1).\n",
        "        target_seq = np.zeros((1, 1))\n",
        "        target_seq[0, 0] = sampled_token_index\n",
        "\n",
        "         # Update states\n",
        "        states_value = [h] # reshape h for next iteration\n",
        "\n",
        "    return ' '.join(translated_sentence)\n",
        "\n",
        "# Evaluate BLEU score on the test set\n",
        "def evaluate_bleu_score(x_test, y_test):\n",
        "    bleu_scores = []\n",
        "    smooth_fn = SmoothingFunction().method1  # Smoothing for short sentences\n",
        "\n",
        "    for i in range(len(x_test)):\n",
        "        input_seq = x_test[i:i+1]\n",
        "        predicted_translation = translate_sequence(input_seq)\n",
        "        actual_translation = sequence_to_text(tokenizer_urdu, y_test[i])\n",
        "\n",
        "        # Remove padding tokens and the start/end tokens\n",
        "        predicted_translation = [word for word in predicted_translation.split() if word not in ['<start>', '<end>', '<unk>']]\n",
        "        actual_translation = [word for word in actual_translation if word not in ['<start>', '<end>', '<unk>', '0']]\n",
        "\n",
        "        # Compute BLEU score\n",
        "        bleu_score = sentence_bleu([actual_translation], predicted_translation, smoothing_function=smooth_fn)\n",
        "        bleu_scores.append(bleu_score)\n",
        "\n",
        "    return np.mean(bleu_scores)\n",
        "\n",
        "# Calculate the accuracy for predictions on the test set\n",
        "def evaluate_accuracy(x_test, y_test):\n",
        "    correct_predictions = 0\n",
        "    total_predictions = 0\n",
        "\n",
        "    for i in range(len(x_test)):\n",
        "        input_seq = x_test[i:i+1]\n",
        "        predicted_translation = translate_sequence(input_seq)\n",
        "        actual_translation = sequence_to_text(tokenizer_urdu, y_test[i])\n",
        "\n",
        "        # Remove padding tokens and the start/end tokens\n",
        "        predicted_translation = [word for word in predicted_translation.split() if word not in ['<start>', '<end>', '<unk>']]\n",
        "        actual_translation = [word for word in actual_translation if word not in ['<start>', '<end>', '<unk>', '0']]\n",
        "\n",
        "        # Update correct and total predictions\n",
        "        correct_predictions += sum(1 for p, a in zip(predicted_translation, actual_translation) if p == a)\n",
        "        total_predictions += len(actual_translation)  # Consider the actual length as the base\n",
        "\n",
        "    accuracy = correct_predictions / total_predictions if total_predictions > 0 else 0\n",
        "    return accuracy\n",
        "\n",
        "# Evaluate BLEU score and accuracy on the test set\n",
        "bleu_score = evaluate_bleu_score(x_test, y_test)\n",
        "accuracy = evaluate_accuracy(x_test, y_test)\n",
        "\n",
        "# Print the results\n",
        "print(f'BLEU Score on Test Set: {bleu_score:.4f}')\n",
        "print(f'Accuracy on Test Set: {accuracy:.4f}')\n"
      ],
      "metadata": {
        "id": "1OeE4j7eQB9W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-JCvViMZTtQ7"
      },
      "source": [
        "### Translating Sentences\n",
        "\n",
        "#### Defining the test function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FQ0nKE9nS8Hm"
      },
      "outputs": [],
      "source": [
        "def translate(text):\n",
        "    # Tokenize and pad the input text\n",
        "    sequence = tokenizer_eng.texts_to_sequences([text])\n",
        "    sequence = pad_sequences(sequence, maxlen=max_len, padding='post')\n",
        "\n",
        "    # Get the encoder states (hidden states) from the encoder\n",
        "    states_value = encoder_model.predict(sequence)\n",
        "\n",
        "    # Prepare the target sequence with the <start> token\n",
        "    target_seq = np.zeros((1, 1))\n",
        "    target_seq[0, 0] = tokenizer_urdu.word_index['<start>']\n",
        "\n",
        "    # Initialize variables\n",
        "    stop_condition = False\n",
        "    translated_text = ''\n",
        "\n",
        "    # Loop to generate the translation iteratively\n",
        "    while not stop_condition:\n",
        "        # Predict the next word in the sequence\n",
        "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
        "\n",
        "        # Get the index of the predicted word\n",
        "        predicted_idx = np.argmax(output_tokens[0, -1, :])\n",
        "        predicted_word = tokenizer_urdu.index_word.get(predicted_idx, '')\n",
        "\n",
        "        # Append the predicted word to the translated text\n",
        "        if predicted_word == '<end>':\n",
        "            stop_condition = True\n",
        "        else:\n",
        "            translated_text += ' ' + predicted_word\n",
        "\n",
        "        # Update the target sequence with the predicted word\n",
        "        target_seq = np.zeros((1, 1))\n",
        "        target_seq[0, 0] = predicted_idx\n",
        "\n",
        "        # Update states\n",
        "        states_value = [h, c]\n",
        "\n",
        "    return translated_text.strip()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q_W8y1_NTtQ7"
      },
      "source": [
        "#### First Five Sentences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vKcfpKRC4yBr"
      },
      "outputs": [],
      "source": [
        "for sentence in df.head()['SENTENCES']:\n",
        "  print(sentence)\n",
        "  print(translate(sentence))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Aarj5ij1TtQ7"
      },
      "source": [
        "## Saving the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "G6izV1_geuil"
      },
      "outputs": [],
      "source": [
        "model.save(\"english_urdu_RNN_f219258.keras\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}